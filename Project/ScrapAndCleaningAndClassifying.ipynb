{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df428bb-68d8-467e-aec2-0a7f111f72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of scraping data from comments \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import re\n",
    "import os\n",
    "import wget\n",
    "import time\n",
    "from splinter import Browser\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762d2ea2-9e23-4a4e-8d39-e563751244fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the Chromedriver executable\n",
    "executable_path = 'C:/Users/lejone/chromedriver.exe'\n",
    "\n",
    "# Set Chrome options and include the executable path\n",
    "chrome_options = Options()\n",
    "chrome_options.executable_path = executable_path\n",
    "\n",
    "# Create a browser instance with Chrome and the specified options\n",
    "browser = Browser('chrome', options=chrome_options)\n",
    "\n",
    "# Navigate to the Facebook login page\n",
    "url = \"https://www.facebook.com/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ad2257-e83e-4210-91e2-ea856a6c812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to a specific Facebook page\n",
    "# url = 'https://web.facebook.com/BritainsGotTalent?_rdc=1&_rdr'\n",
    "# url = 'https://www.facebook.com/MejametalanaNewsroom'\n",
    "# url = 'https://www.facebook.com/groups/585988568211873'\n",
    "# url = 'https://www.facebook.com/profile.php?id=61551520045088'\n",
    "url = 'https://web.facebook.com/VodacomLesotho'\n",
    "# url = 'https://www.facebook.com/search/top?q=bosslogic'\n",
    "# browser.visit(url)\n",
    "\n",
    "# scroll down to load more results\n",
    "scroll_count = 3\n",
    "scroll_delay = 2\n",
    "\n",
    "for _ in range(scroll_count):\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_delay)\n",
    "\n",
    "# Parser the HTML\n",
    "html = browser.html\n",
    "# creating a BeautifulSoup object from the scrapped HTML\n",
    "page_soup = soup(html, 'html.parser')\n",
    "\n",
    "# check if HTML was scrapped correctly\n",
    "# print(page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31271e3d-b4f6-408f-ba75-a1088590777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "# extracting necessary data/info and insert into lists AND CLEANING\n",
    "caption_box = page_soup.find_all('div', class_=\"x1iorvi4 x1pi30zi x1l90r2v x1swvt13\")\n",
    "caption_list = [caption.text.strip() for caption in caption_box]\n",
    "\n",
    "name_box = page_soup.find_all('span', class_=\"xt0psk2\")\n",
    "name_list = [name.text.strip() for name in name_box]\n",
    "\n",
    "comment_box = page_soup.find_all('div', class_=\"x1lliihq xjkvuk6 x1iorvi4\")\n",
    "comment_list = [comment.text.strip() for comment in comment_box]\n",
    "\n",
    "# comment_list, caption_list, name_list\n",
    "comment_list\n",
    "\n",
    "import csv\n",
    "# Open a CSV file in append mode\n",
    "with open('output.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Iterate through the data list and write each row\n",
    "    for comment in comment_list:\n",
    "        writer.writerow([comment])\n",
    "\n",
    "print(\"Data saved to output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c57cfd1-6bc7-495d-aec6-958c960969f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Gauteng re e thola joang rea kopa',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('Hake lebetse password??',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('Hakea staka',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Congratulations Mme Mathabelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Comment\n",
       "0    ('Gauteng re e thola joang rea kopa',)\n",
       "1              ('Hake lebetse password??',)\n",
       "2                          ('Hakea staka',)\n",
       "3                                     ('',)\n",
       "4                                     Phoka\n",
       "..                                      ...\n",
       "103                                     NaN\n",
       "104           Congratulations Mme Mathabelo\n",
       "105                                     NaN\n",
       "106                                     NaN\n",
       "107                                     NaN\n",
       "\n",
       "[108 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df = pd.read_csv('output.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1869d7-d4df-4892-ae34-dda8b2588e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Cleaned_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Congratulations Mme Mathabelo</td>\n",
       "      <td>congratulation mme mathabelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Comment               Cleaned_Comment\n",
       "103                            NaN                              \n",
       "104  Congratulations Mme Mathabelo  congratulation mme mathabelo\n",
       "105                            NaN                              \n",
       "106                            NaN                              \n",
       "107                            NaN                              "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Check if the text is NaN\n",
    "    if pd.isna(text): \n",
    "        # Return an empty string if NaN\n",
    "        return ''  \n",
    "    else:\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "        \n",
    "        # Lemmatize tokens\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        # Join tokens back into a cleaned text\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "        \n",
    "        return cleaned_text\n",
    "\n",
    "# Apply the preprocessing function to the 'Comment' column and create a new column 'Cleaned_Comment'\n",
    "df['Cleaned_Comment'] = df['Comment'].apply(preprocess_text)\n",
    "\n",
    "# Display the first or few few rows of the DataFrame to verify the data including the cleaned data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0208b9da-f44c-46ea-8551-5812274f19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well saved to csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Cleaned_Comment</th>\n",
       "      <th>bullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Gauteng re e thola joang rea kopa',)</td>\n",
       "      <td>( 'gauteng e thola joang rea kopa ' , )</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('Hake lebetse password??',)</td>\n",
       "      <td>( 'hake lebetse password ? ? ' , )</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('Hakea staka',)</td>\n",
       "      <td>( 'hakea staka ' , )</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('',)</td>\n",
       "      <td>( `` , )</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoka</td>\n",
       "      <td>phoka</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1. She scratches her nose, mouth, or ear more ...</td>\n",
       "      <td>1. scratch nose , mouth , ear frequently.2 . b...</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Ťőmåĺ Müsțąfā nice</td>\n",
       "      <td>ťőmåĺ müsțąfā nice</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Hao buwa  ka monna ya ratang batho ebile aba h...</td>\n",
       "      <td>hao buwa ka monna ya ratang batho ebile aba hl...</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Themba Noseballkea leboha hlee my brother</td>\n",
       "      <td>themba noseballkea leboha hlee brother</td>\n",
       "      <td>bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Qualified tutor and a degree holder in compute...</td>\n",
       "      <td>qualified tutor degree holder computer science...</td>\n",
       "      <td>non-bully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment  \\\n",
       "0              ('Gauteng re e thola joang rea kopa',)   \n",
       "1                        ('Hake lebetse password??',)   \n",
       "2                                    ('Hakea staka',)   \n",
       "3                                               ('',)   \n",
       "4                                               Phoka   \n",
       "..                                                ...   \n",
       "80  1. She scratches her nose, mouth, or ear more ...   \n",
       "81                                 Ťőmåĺ Müsțąfā nice   \n",
       "82  Hao buwa  ka monna ya ratang batho ebile aba h...   \n",
       "83          Themba Noseballkea leboha hlee my brother   \n",
       "84  Qualified tutor and a degree holder in compute...   \n",
       "\n",
       "                                      Cleaned_Comment bullying_type  \n",
       "0             ( 'gauteng e thola joang rea kopa ' , )         bully  \n",
       "1                  ( 'hake lebetse password ? ? ' , )         bully  \n",
       "2                                ( 'hakea staka ' , )         bully  \n",
       "3                                            ( `` , )         bully  \n",
       "4                                               phoka         bully  \n",
       "..                                                ...           ...  \n",
       "80  1. scratch nose , mouth , ear frequently.2 . b...         bully  \n",
       "81                                 ťőmåĺ müsțąfā nice         bully  \n",
       "82  hao buwa ka monna ya ratang batho ebile aba hl...     non-bully  \n",
       "83             themba noseballkea leboha hlee brother         bully  \n",
       "84  qualified tutor degree holder computer science...     non-bully  \n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load your trained model (it was saved using joblib)\n",
    "loaded_model = joblib.load('C:/Users/lejone/Desktop/New folder/kha90.joblib')  \n",
    "\n",
    "# Load the dataset into a DataFrame ('output.csv' contains dataset of scrpped data)\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Check if the text is NaN\n",
    "    if pd.isna(text): \n",
    "        # Return an empty string if NaN\n",
    "        return ''  \n",
    "    else:\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "        \n",
    "        # Lemmatize tokens\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        # Join tokens back into a cleaned text\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "        \n",
    "        return cleaned_text\n",
    "\n",
    "# Apply the text preprocessing function to the 'Comment' column and create a new column 'Cleaned_Comment'\n",
    "df['Cleaned_Comment'] = df['Comment'].apply(preprocess_text)\n",
    "\n",
    "# Use the trained model to predict the 'bullying_type' for each text\n",
    "df['bullying_type'] = df['Cleaned_Comment'].apply(lambda x: loaded_model.predict([x])[0])\n",
    "\n",
    "# Save the DataFrame with the predicted 'bullying_type' column to a new CSV file\n",
    "df.to_csv('output_with_predictions.csv', index=False)\n",
    "print(\"Well saved to csv\")\n",
    "# Display the DataFrame with the predicted 'bullying_type' column\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b08fc-cfbd-4753-992e-7d6e6b30d157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
